{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % reset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data and pre-process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test)=mnist.load_data()\n",
    "X_train.shape , y_train.shape , X_test.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_input_img(i):\n",
    "    plt.imshow(X_train[i] , cmap = 'binary')\n",
    "    plt.title(y_train[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Process the images\n",
    "\n",
    "# Normalizing the image to [0 , 1] range\n",
    "X_train = X_train.astype(np.float32)/255\n",
    "X_test = X_test.astype(np.float32)/255\n",
    "\n",
    "# Reshape / expand the dimetions of image to (28,28,1)\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "\n",
    "#  convert classes to one hot vectors\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3),input_shape = (28,28,1),activation='relu',padding='same'),)\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                23050     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,866\n",
      "Trainable params: 41,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss = keras.losses.categorical_crossentropy , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "\n",
    "from keras.callbacks import EarlyStopping , ModelCheckpoint\n",
    "\n",
    "# Earlystopping\n",
    "\n",
    "es= EarlyStopping(monitor='val_accuracy', min_delta=0.01,patience=4,verbose=1)\n",
    "\n",
    "# Model Check Point\n",
    "\n",
    "mc = ModelCheckpoint(\"temp/bestmodel.h5\",monitor=\"val_accuracy\",verbose=1, save_best_only= True)\n",
    "\n",
    "cb = [es , mc]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2644 - accuracy: 0.9205\n",
      "Epoch 1: val_accuracy improved from -inf to 0.97217, saving model to temp\\bestmodel.h5\n",
      "657/657 [==============================] - 21s 32ms/step - loss: 0.2643 - accuracy: 0.9205 - val_loss: 0.0917 - val_accuracy: 0.9722\n",
      "Epoch 2/10\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0825 - accuracy: 0.9748\n",
      "Epoch 2: val_accuracy improved from 0.97217 to 0.97789, saving model to temp\\bestmodel.h5\n",
      "657/657 [==============================] - 22s 33ms/step - loss: 0.0825 - accuracy: 0.9747 - val_loss: 0.0713 - val_accuracy: 0.9779\n",
      "Epoch 3/10\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0630 - accuracy: 0.9805\n",
      "Epoch 3: val_accuracy improved from 0.97789 to 0.98383, saving model to temp\\bestmodel.h5\n",
      "657/657 [==============================] - 21s 32ms/step - loss: 0.0631 - accuracy: 0.9805 - val_loss: 0.0536 - val_accuracy: 0.9838\n",
      "Epoch 4/10\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0504 - accuracy: 0.9845\n",
      "Epoch 4: val_accuracy improved from 0.98383 to 0.98472, saving model to temp\\bestmodel.h5\n",
      "657/657 [==============================] - 22s 34ms/step - loss: 0.0503 - accuracy: 0.9845 - val_loss: 0.0494 - val_accuracy: 0.9847\n",
      "Epoch 5/10\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0431 - accuracy: 0.9867\n",
      "Epoch 5: val_accuracy improved from 0.98472 to 0.98644, saving model to temp\\bestmodel.h5\n",
      "657/657 [==============================] - 25s 38ms/step - loss: 0.0430 - accuracy: 0.9867 - val_loss: 0.0470 - val_accuracy: 0.9864\n",
      "Epoch 6/10\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.9874\n",
      "Epoch 6: val_accuracy did not improve from 0.98644\n",
      "657/657 [==============================] - 25s 39ms/step - loss: 0.0388 - accuracy: 0.9874 - val_loss: 0.0447 - val_accuracy: 0.9863\n",
      "Epoch 7/10\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0322 - accuracy: 0.9897\n",
      "Epoch 7: val_accuracy improved from 0.98644 to 0.98750, saving model to temp\\bestmodel.h5\n",
      "657/657 [==============================] - 24s 36ms/step - loss: 0.0322 - accuracy: 0.9897 - val_loss: 0.0422 - val_accuracy: 0.9875\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "his = model.fit(X_train, y_train,epochs=10,validation_split=0.3, callbacks=cb ,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_S = keras.models.load_model(\"temp/bestmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0304 - accuracy: 0.9899\n",
      " the model accuracy is 0.9898999929428101\n"
     ]
    }
   ],
   "source": [
    "score = model_S.evaluate(X_test,y_test)\n",
    "\n",
    "print(f\" the model accuracy is {score[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# lab_rand = class_names[np.random.randint(0,47)] #50種挑其中一類\n",
    "# testdir = os.path.join(base_dirtest,lab_rand) #選出所在種類的資料路徑\n",
    "# #選出其中一張照片的路徑\n",
    "# testimg=os.path.join(testdir,os.listdir(testdir)[np.random.randint(0,len(testdir)-1)]) \n",
    "# x = image.load_img(testimg,target_size=(img_size,img_size))\n",
    "# #模型輸出種類及預測機率 top-5\n",
    "# x = np.expand_dims(x, axis = 0) \n",
    "# pred = model.predict(x)[0]\n",
    "# top_inds = pred.argsort()[::-1][:5]\n",
    "# for i in top_inds:\n",
    "#   print('    {:.3f}  {}'.format(pred[i], class_names[i]))\n",
    "# plt.subplot(1, 1, 1)\n",
    "# image = cv2.imread(testimg)\n",
    "# image = image[:,:,::-1]\n",
    "# plt.imshow(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
